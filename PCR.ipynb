{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbcQnomtoMkXg+XwloiKyZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrbarik/PrincipalComponentRegression/blob/main/PCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pincipal Compoenent Regression**"
      ],
      "metadata": {
        "id": "J3fshsXpMS0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Import Necessary Packages**"
      ],
      "metadata": {
        "id": "pJ-Spfw9M4mG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzSm5sJgMRPs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import scale \n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Load the Data**\n",
        "\n",
        "For this example, we’ll use a dataset called mtcars, which contains information about 33 different cars. We’ll use hp as the response variable and the following variables as the predictors:\n",
        "\n",
        "*   mpg\n",
        "*   disp\n",
        "*   drat\n",
        "*   wt\n",
        "*.  qsec\n",
        "\n",
        "The following code shows how to load and view this dataset:"
      ],
      "metadata": {
        "id": "KnSMbEm_NA9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define URL where data is located\n",
        "url = \"https://raw.githubusercontent.com/Statology/Python-Guides/main/mtcars.csv\"\n",
        "\n",
        "#read in data\n",
        "data_full = pd.read_csv(url)\n",
        "\n",
        "#select subset of data\n",
        "data = data_full[[\"mpg\", \"disp\", \"drat\", \"wt\", \"qsec\", \"hp\"]]\n",
        "\n",
        "#view first six rows of data\n",
        "data[0:6]"
      ],
      "metadata": {
        "id": "onFcFkwYNqHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Fit the PCR Model**\n",
        "\n",
        "The following code shows how to fit the PCR model to this data. Note the following:\n",
        "\n",
        "***pca.fit_transform(scale(X)):*** This tells Python that each of the predictor variables should be scaled to have a mean of 0 and a standard deviation of 1. This ensures that no predictor variable is overly influential in the model if it happens to be measured in different units.\n",
        "\n",
        "***cv = RepeatedKFold():*** This tells Python to use k-fold cross-validation to evaluate the performance of the model. For this example we choose k = 10 folds, repeated 3 times."
      ],
      "metadata": {
        "id": "2eAwEH1XOAHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define predictor and response variables\n",
        "X = data[[\"mpg\", \"disp\", \"drat\", \"wt\", \"qsec\"]]\n",
        "y = data[[\"hp\"]]\n",
        "\n",
        "# scale predictor variables\n",
        "pca = PCA()\n",
        "X_reduced = pca.fit_transform(scale(X))\n",
        "\n",
        "# define cross validation method\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "regr = LinearRegression()\n",
        "mse = []\n",
        "\n",
        "# Calculate MSE with only the intercept\n",
        "score = -1 * model_selection.cross_val_score(regr,\n",
        "           np.ones((len(X_reduced),1)), y, cv = cv,\n",
        "           scoring='neg_mean_squared_error').mean()    \n",
        "mse.append(score)\n",
        "\n",
        "# Calculate MSE using cross-validation, adding one component at a time\n",
        "for i in np.arange(1, 6):\n",
        "    score = -1*model_selection.cross_val_score(regr,\n",
        "               X_reduced[:,:i], y, cv=cv, scoring='neg_mean_squared_error').mean()\n",
        "    mse.append(score)\n",
        "    \n",
        "# Plot cross-validation results    \n",
        "plt.plot(mse)\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('hp')"
      ],
      "metadata": {
        "id": "HSHg-42QOKXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot displays the number of principal components along the x-axis and the test MSE (mean squared error) along the y-axis.\n",
        "\n",
        "From the plot we can see that the test MSE decreases by adding in two principal components, yet it begins to increase as we add more than two principal components.\n",
        "\n",
        "Thus, the optimal model includes just the first two principal components.\n",
        "\n",
        "We can also use the following code to calculate the percentage of variance in the response variable explained by adding in each principal component to the model:\n"
      ],
      "metadata": {
        "id": "SBBggTz1OkSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
        "\n",
        "array([69.83, 89.35, 95.88, 98.95, 99.99])"
      ],
      "metadata": {
        "id": "Uq03RLYGO5Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the following:\n",
        "\n",
        "By using just the first principal component, we can explain 69.83% of the variation in the response variable.\n",
        "\n",
        "By adding in the second principal component, we can explain 89.35% of the variation in the response variable.\n",
        "\n",
        "Note that we’ll always be able to explain more variance by using more principal components, but we can see that adding in more than two principal components doesn’t actually increase the percentage of explained variance by much."
      ],
      "metadata": {
        "id": "kxiFEL5mPGWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Use the Final Model to Make Predictions**\n",
        "\n",
        "We can use the final PCR model with two principal components to make predictions on new observations.\n",
        "\n",
        "The following code shows how to split the original dataset into a training and testing set and use the PCR model with two principal components to make predictions on the testing set."
      ],
      "metadata": {
        "id": "rhRmM8kVPRYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split the dataset into training (70%) and testing (30%) sets\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0) \n",
        "\n",
        "#scale the training and testing data\n",
        "X_reduced_train = pca.fit_transform(scale(X_train))\n",
        "X_reduced_test = pca.transform(scale(X_test))[:,:1]\n",
        "\n",
        "#train PCR model on training data \n",
        "regr = LinearRegression()\n",
        "regr.fit(X_reduced_train[:,:1], y_train)\n",
        "\n",
        "#calculate RMSE\n",
        "pred = regr.predict(X_reduced_test)\n",
        "np.sqrt(mean_squared_error(y_test, pred))"
      ],
      "metadata": {
        "id": "-mu-h5PPPMVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the test RMSE turns out to be 40.2096. This is the average deviation between the predicted value for hp and the observed value for hp for the observations in the testing set."
      ],
      "metadata": {
        "id": "UCwdZVDzPg-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete Code:"
      ],
      "metadata": {
        "id": "2oPMOV7fPrJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import scale \n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#define URL where data is located\n",
        "url = \"https://raw.githubusercontent.com/Statology/Python-Guides/main/mtcars.csv\"\n",
        "\n",
        "#read in data\n",
        "data_full = pd.read_csv(url)\n",
        "\n",
        "#select subset of data\n",
        "data = data_full[[\"mpg\", \"disp\", \"drat\", \"wt\", \"qsec\", \"hp\"]]\n",
        "\n",
        "#view first six rows of data\n",
        "data[0:6]\n",
        "#define predictor and response variables\n",
        "X = data[[\"mpg\", \"disp\", \"drat\", \"wt\", \"qsec\"]]\n",
        "y = data[[\"hp\"]]\n",
        "\n",
        "#scale predictor variables\n",
        "pca = PCA()\n",
        "X_reduced = pca.fit_transform(scale(X))\n",
        "\n",
        "#define cross validation method\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "regr = LinearRegression()\n",
        "mse = []\n",
        "\n",
        "# Calculate MSE with only the intercept\n",
        "score = -1*model_selection.cross_val_score(regr, np.ones((len(X_reduced),1)), y, cv=cv, scoring='neg_mean_squared_error').mean()    \n",
        "mse.append(score)\n",
        "\n",
        "# Calculate MSE using cross-validation, adding one component at a time\n",
        "for i in np.arange(1, 6):\n",
        "    score = -1*model_selection.cross_val_score(regr, X_reduced[:,:i], y, cv=cv, scoring='neg_mean_squared_error').mean()\n",
        "    mse.append(score)\n",
        "    \n",
        "# Plot cross-validation results    \n",
        "plt.plot(mse)\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('hp')\n",
        "\n",
        "#calculate percentage of variation explained\n",
        "np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
        "\n",
        "#split the dataset into training (70%) and testing (30%) sets\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0) \n",
        "\n",
        "#scale the training and testing data\n",
        "X_reduced_train = pca.fit_transform(scale(X_train))\n",
        "X_reduced_test = pca.transform(scale(X_test))[:,:1]\n",
        "\n",
        "#train PCR model on training data \n",
        "regr = LinearRegression()\n",
        "regr.fit(X_reduced_train[:,:1], y_train)\n",
        "\n",
        "#calculate RMSE\n",
        "pred = regr.predict(X_reduced_test)\n",
        "np.sqrt(mean_squared_error(y_test, pred))"
      ],
      "metadata": {
        "id": "JsYcGmH6PvSA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
